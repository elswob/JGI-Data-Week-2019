{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To recap\n",
    "\n",
    "### Data so far\n",
    "\n",
    "1. We have created a list of people and their ORCID identifiers - [output/pure_person_to_orcid.txt](output/pure_person_to_orcid.txt)\n",
    "2. We have created a list of ORCID to PubMed identifiers - [output/orcid.tsv](output/orcid.tsv)\n",
    "3. We have created a list of PubMed IDs to PubMed info - [output/pubmed.tsv](output/pubmed.tsv)\n",
    "4. We have created a list of the top 100 terms for each person - [output/orcid-tf-idf.txt](output/orcid-tf-idf.txt)\n",
    "\n",
    "### Questions\n",
    "\n",
    "Now we need to use the common identifiers in these data to answer some questions:\n",
    "\n",
    "1. Can we produce a set of potential collaborators for each person, a collaborator being someone they have significant terms in common with but not previously published with.\n",
    "2. Can we select a set of people that most closely map to a specific piece of text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas dataframes\n",
    "\n",
    "Normally at this point we would use a database. However, to keep it all in a single language and framework, and as the data themselves are relatively small, we can use pandas - https://pandas.pydata.org/\n",
    "\n",
    ">pandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, following on from the data descriptions above:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(898, 2)\n",
      "                         pure_person_id             orcid_id\n",
      "0  4ec18a96-fd2e-4311-a6fa-7ec65696a4e9  0000-0003-3108-5775\n",
      "1  7a04c325-7a39-4560-8308-8cbcaa763747  0000-0002-6772-7111\n",
      "2  b4014828-88e9-4861-ae1d-5c369b6ae35a  0000-0001-7328-4233\n",
      "3  ccedc4d6-6d7e-4a60-8313-f59409ecc6dd  0000-0001-6224-3073\n",
      "4  66e3df0f-6cbe-4cf4-a034-9e1b57684f6b  0000-0003-0300-4990\n",
      "(15722, 2)\n",
      "              orcid_id      pmid\n",
      "0  0000-0001-5001-3350  26961927\n",
      "1  0000-0001-5001-3350  30605491\n",
      "2  0000-0001-5008-0705  29118635\n",
      "3  0000-0001-5017-9473  18194108\n",
      "4  0000-0001-5017-9473  18607707\n",
      "(11160, 4)\n",
      "       pmid  year                                              title  \\\n",
      "0  25475436  2015  Sixty-five common genetic variants and predict...   \n",
      "1  25011450  2014  Association between alcohol and cardiovascular...   \n",
      "2  28968714  2018  FATHMM-XF: accurate prediction of pathogenic p...   \n",
      "3  21965548  2012  Four genetic loci influencing electrocardiogra...   \n",
      "4  26930047  2016  Diagnosis of Coronary Heart Diseases Using Gen...   \n",
      "\n",
      "                                            abstract  \n",
      "0  We developed a 65 type 2 diabetes (T2D) varian...  \n",
      "1  To use the rs1229984 variant in the alcohol de...  \n",
      "2  We present FATHMM-XF, a method for predicting ...  \n",
      "3  Presence of left ventricular hypertrophy on an...  \n",
      "4  Cardiovascular disease (including coronary art...  \n",
      "(52546, 3)\n",
      "              orcid_id             term    tf-idf\n",
      "0  0000-0003-0924-3247      methylation  0.201768\n",
      "1  0000-0003-0924-3247         variants  0.139032\n",
      "2  0000-0003-0924-3247             loci  0.138066\n",
      "3  0000-0003-0924-3247          genetic  0.136506\n",
      "4  0000-0003-0924-3247  dna methylation  0.127503\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. People and their ORCID identifiers \n",
    "personToOrcid = pd.read_csv('data/pure_person_to_orcid.txt',sep='\\t')\n",
    "print(personToOrcid.shape)\n",
    "print(personToOrcid.head())\n",
    "\n",
    "# 2. ORCID to PubMed identifiers\n",
    "orcidToPubmed = pd.read_csv('data/orcid.tsv',sep='\\t')\n",
    "print(orcidToPubmed.shape)\n",
    "print(orcidToPubmed.head())\n",
    "\n",
    "# 3. PubMed IDs to PubMed info\n",
    "pubmedToInfo = pd.read_csv('data/pubmed.tsv',sep='\\t')\n",
    "print(pubmedToInfo.shape)\n",
    "print(pubmedToInfo.head())\n",
    "\n",
    "# 4. Top 100 terms for each person\n",
    "topTerms = pd.read_csv('data/orcid-tf-idf.txt',sep='\\t')\n",
    "print(topTerms.shape)\n",
    "print(topTerms.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first pass would be to count the number of matching terms between each person. To start with, let's just compare the first in the list to everyone else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Comparing 0 4ec18a96-fd2e-4311-a6fa-7ec65696a4e9 0000-0003-3108-5775\n",
      "0000-0001-7086-8882 ['polar vortices', 'titans winter', 'rapid mesospheric cooling', 'relatively long atmospheric', 'polar vortex formation', 'solar heating', 'vortex formation 20102011', 'unexpected rapid mesospheric', 'radiative cooling efficiency', 'temperatures 26 years', 'produced mesospheric hotspot', 'postequinox cooling far', 'trace gases 2012', 'extreme', 'vortex configuration results', 'polar vortex saturns', 'titans', 'formation', 'spring equinox', 'rapid mesospheric', 'unusually cold', 'winter polar vortex', 'stable vortex configuration', 'seasonal effects', 'saturns', 'strong seasonal effects', 'vortices following', 'subsidence winter polar', 'postequinox long', 'saturns largest', 'timeframe reach stable', 'southpolar subsidence', 'produced mesospheric', 'postequinox', 'enrichment', 'radiative time', 'subsidence', 'southpolar', 'trace', 'subsidence winter', 'trace gases relatively', 'polar vortices following', 'subsidence produced', 'strengthening subsidence produced', 'spring equinox peak', 'strengthening subsidence', 'vortex dramatically', 'years postequinox long', 'titans 2009', 'vortex formation', 'winter', 'winter polar', 'radiative', 'stable vortex', 'northern', 'results high infrared', 'vortex saturns', 'substantial nitrogenmethane', 'polar', 'southpolar subsidence winter', 'produced trace', 'titans winter polar', 'vortex configuration', 'reach stable vortex', 'vortex', 'seasonal effects including', 'postequinox long timeframe', 'trace gas enrichment', 'vortices following titans', 'postequinox cooling', 'winter polar vortices', 'titans 2009 northern', 'saturns largest moon', 'titans trace gases', 'titans trace', 'radiative time constant', 'vortex dramatically increases', 'subsidence produced mesospheric', 'unique titan', 'long', 'titan substantial', 'unusually cold temperatures', 'winter polar hotspots', 'trace gases', 'unexpected rapid', 'titan substantial nitrogenmethane', 'radiative cooling', 'solar heating moved', 'years postequinox', 'gases', 'substantial nitrogenmethane atmosphere', 'polar vortex', 'temperatures 26', 'time constant winter', 'cooling', 'produced trace gases', 'titan', 'vortex saturns largest', 'timeframe reach', 'mesospheric']\n"
     ]
    }
   ],
   "source": [
    " #loop through people (limit to top 1)\n",
    "def compare_people(limit):\n",
    "    for i, iData in personToOrcid.head(n=limit).iterrows():\n",
    "        print('### Comparing',i,iData.pure_person_id,iData.orcid_id)\n",
    "        #get all terms and tf-idf values\n",
    "        iTopTerms=topTerms[topTerms['orcid_id']==iData.orcid_id]\n",
    "        #print(iTopTerms.head())\n",
    "        iTerms = iTopTerms['term']\n",
    "\n",
    "        for j in range(i+1,personToOrcid.shape[0]):\n",
    "            jData=personToOrcid.iloc[j]\n",
    "            jTopTerms=topTerms[topTerms['orcid_id']==jData.orcid_id]\n",
    "            #print(jTopTerms['term'].head())\n",
    "            jTerms = jTopTerms['term']\n",
    "            #print(iTerms,jTerms)\n",
    "            com = list(set(iTerms) & set(jTerms))\n",
    "            #only show maches with more than 1 matching term\n",
    "            if len(com) > 1:\n",
    "                print(jData.orcid_id,com)\n",
    "    \n",
    "compare_people(1)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are few matches with many overlapping terms, except one **0000-0001-7086-8882**. Let's look at the research pages of these two people\n",
    "\n",
    "https://research-information.bristol.ac.uk/en/persons/melody-a-s-sylvestre(81e7f06c-77d8-4020-9608-0b30dd001c43)/publications.html https://research-information.bristol.ac.uk/en/persons/nicholas-a-teanby(4ec18a96-fd2e-4311-a6fa-7ec65696a4e9)/publications.html \n",
    "\n",
    "This suggests they are from similar research areas, and have indeed co-published.   \n",
    "\n",
    "Let's try again, this time with the top 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_people(3)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second person matched no-one, the third however matched quite a few. Let's modify the function to sort by number:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Comparing 0 4ec18a96-fd2e-4311-a6fa-7ec65696a4e9 0000-0003-3108-5775\n",
      "('0000-0001-7086-8882', ['polar vortices', 'titans winter', 'rapid mesospheric cooling', 'relatively long atmospheric', 'polar vortex formation', 'solar heating', 'vortex formation 20102011', 'unexpected rapid mesospheric', 'radiative cooling efficiency', 'temperatures 26 years', 'produced mesospheric hotspot', 'postequinox cooling far', 'trace gases 2012', 'extreme', 'vortex configuration results', 'polar vortex saturns', 'titans', 'formation', 'spring equinox', 'rapid mesospheric', 'unusually cold', 'winter polar vortex', 'stable vortex configuration', 'seasonal effects', 'saturns', 'strong seasonal effects', 'vortices following', 'subsidence winter polar', 'postequinox long', 'saturns largest', 'timeframe reach stable', 'southpolar subsidence', 'produced mesospheric', 'postequinox', 'enrichment', 'radiative time', 'subsidence', 'southpolar', 'trace', 'subsidence winter', 'trace gases relatively', 'polar vortices following', 'subsidence produced', 'strengthening subsidence produced', 'spring equinox peak', 'strengthening subsidence', 'vortex dramatically', 'years postequinox long', 'titans 2009', 'vortex formation', 'winter', 'winter polar', 'radiative', 'stable vortex', 'northern', 'results high infrared', 'vortex saturns', 'substantial nitrogenmethane', 'polar', 'southpolar subsidence winter', 'produced trace', 'titans winter polar', 'vortex configuration', 'reach stable vortex', 'vortex', 'seasonal effects including', 'postequinox long timeframe', 'trace gas enrichment', 'vortices following titans', 'postequinox cooling', 'winter polar vortices', 'titans 2009 northern', 'saturns largest moon', 'titans trace gases', 'titans trace', 'radiative time constant', 'vortex dramatically increases', 'subsidence produced mesospheric', 'unique titan', 'long', 'titan substantial', 'unusually cold temperatures', 'winter polar hotspots', 'trace gases', 'unexpected rapid', 'titan substantial nitrogenmethane', 'radiative cooling', 'solar heating moved', 'years postequinox', 'gases', 'substantial nitrogenmethane atmosphere', 'polar vortex', 'temperatures 26', 'time constant winter', 'cooling', 'produced trace gases', 'titan', 'vortex saturns largest', 'timeframe reach', 'mesospheric'])\n",
      "### Comparing 1 7a04c325-7a39-4560-8308-8cbcaa763747 0000-0002-6772-7111\n",
      "### Comparing 2 b4014828-88e9-4861-ae1d-5c369b6ae35a 0000-0001-7328-4233\n",
      "('0000-0003-1072-0223', ['functional', 'freeliving', 'cellular', 'genome', 'genomes', 'data', 'genes', 'analysis', 'diversity', 'sequence', 'molecular'])\n",
      "('0000-0003-3116-7463', ['genome', 'mirna', 'data', 'species', 'development', 'clades', 'diversity', 'taxa', 'using', 'molecular'])\n",
      "('0000-0003-0924-3247', ['functional', 'genome', 'data', 'genes', 'analysis', 'potential', 'cancer', 'using', 'score'])\n",
      "('0000-0002-9732-5738', ['nematode species', 'data', 'species', 'nematodes', 'parasitic', 'diversity', 'nematode', 'using'])\n",
      "('0000-0001-7382-2855', ['different', 'data', 'database', 'analysis', 'diversity', 'using', 'molecular'])\n",
      "('0000-0002-5311-6213', ['genome', 'genomes', 'data', 'sequence', 'analysis', 'diversity', 'using'])\n",
      "('0000-0003-4611-8795', ['genome', 'cellular', 'data', 'genes', 'analysis', 'cell', 'sequence'])\n",
      "('0000-0003-2052-4840', ['genome', 'data', 'development', 'genes', 'analysis', 'cancer', 'using'])\n",
      "('0000-0003-0920-1055', ['genome', 'data', 'ld', 'genes', 'analysis', 'heritability', 'using'])\n",
      "('0000-0002-2618-750X', ['functional', 'data', 'analysis', 'species', 'taxa', 'using'])\n"
     ]
    }
   ],
   "source": [
    "def compare_people(limit):\n",
    "    for i, iData in personToOrcid.head(n=limit).iterrows():\n",
    "        print('### Comparing',i,iData.pure_person_id,iData.orcid_id)\n",
    "        #get all terms and tf-idf values\n",
    "        iTopTerms=topTerms[topTerms['orcid_id']==iData.orcid_id]\n",
    "        iTerms = iTopTerms['term']\n",
    "        jComp={}\n",
    "        for j in range(i+1,personToOrcid.shape[0]):\n",
    "            jData=personToOrcid.iloc[j]\n",
    "            jTopTerms=topTerms[topTerms['orcid_id']==jData.orcid_id]\n",
    "            jTerms = jTopTerms['term']\n",
    "            com = list(set(iTerms) & set(jTerms))\n",
    "            #only show maches with more than 1 matching term\n",
    "            if len(com) > 1:\n",
    "                jComp[jData.orcid_id]=com\n",
    "        #create sorted dictionary using number of items\n",
    "        jComp = sorted(jComp.items(), key=lambda kv: len(kv[1]), reverse=True)\n",
    "        for p in jComp[0:10]:\n",
    "            print(p)\n",
    "            \n",
    "compare_people(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This only shows us terms that are in common. It could be possible to have lots of terms in common, but these terms are not the 'most' representative of either person. It would be better to compare all terms, and their tf-idf values.\n",
    "\n",
    "Back in the TF-IDF section (http://localhost:8888/lab#TF-IDF-using-sklearn) we created a similarity matrix from the TF-IDF model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000-0003-0924-3247\n",
      "\t 0000-0003-0924-3247 0.9999999999997207\n",
      "\t 0000-0002-1407-8314 0.618225606944109\n",
      "\t 0000-0002-7141-9189 0.5897571412339664\n",
      "\t 0000-0003-2052-4840 0.5690516398208536\n",
      "\t 0000-0002-6793-2262 0.531473900766906\n",
      "0000-0001-7328-4233\n",
      "\t 0000-0001-7328-4233 1.0000000000000322\n",
      "\t 0000-0003-0920-1055 0.11566240835056221\n",
      "\t 0000-0003-0924-3247 0.11331746330572383\n",
      "\t 0000-0002-7141-9189 0.11135289016971364\n",
      "\t 0000-0002-4680-3517 0.10955988442674883\n",
      "0000-0001-5001-3350\n",
      "\t 0000-0001-5001-3350 0.9999999999999893\n",
      "\t 0000-0002-1407-8314 0.15759457124910695\n",
      "\t 0000-0003-2052-4840 0.12386681519489502\n",
      "\t 0000-0003-0920-1055 0.10839962131879305\n",
      "\t 0000-0002-7141-9189 0.09669331068447609\n"
     ]
    }
   ],
   "source": [
    "#get similarity matrix for all people\n",
    "\n",
    "matrixCom = {}\n",
    "\n",
    "#get tfidf matrix and orcidText dictionary\n",
    "%store -r matrix\n",
    "%store -r token_dict\n",
    "\n",
    "for i in range(0,len(matrix)):\n",
    "    iOrcid=list(token_dict)[i]\n",
    "    matrixCom[iOrcid]={}\n",
    "    for j in range(0,len(matrix)):\n",
    "        jOrcid=list(token_dict)[j]\n",
    "        matrixCom[iOrcid][jOrcid]=matrix[i][j]\n",
    "\n",
    "o = open('output/orcid-to-orcid-tf-idf.tsv','w')\n",
    "o.write('orcid_1\\torcid_2\\ttf-idf\\n')\n",
    "counter=0\n",
    "for m in matrixCom:\n",
    "    sorted_res = sorted(matrixCom[m].items(), key=lambda kv: kv[1], reverse=True)\n",
    "    if counter<3:\n",
    "        print(m)\n",
    "        for s in sorted_res[0:5]:\n",
    "            print('\\t',s[0],s[1])\n",
    "        counter+=1\n",
    "    for s in sorted_res:\n",
    "        o.write(m+'\\t'+s[0]+'\\t'+str(s[1])+'\\n')\n",
    "o.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaboration recommendation engine\n",
    "\n",
    "This similarity data depicts the similarity between each person's publication text based on tf-idf. Often, similarities arise due to co-publication, and perhaps a more informative recommender would be to idenfity cases where people have signficant overlap in their publication text, but have never previously co-published. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(279841, 3)\n",
      "               orcid_1              orcid_2    tf-idf\n",
      "0  0000-0003-0924-3247  0000-0003-0924-3247  1.000000\n",
      "1  0000-0003-0924-3247  0000-0002-1407-8314  0.618226\n",
      "2  0000-0003-0924-3247  0000-0002-7141-9189  0.589757\n",
      "3  0000-0003-0924-3247  0000-0003-2052-4840  0.569052\n",
      "4  0000-0003-0924-3247  0000-0002-6793-2262  0.531474\n"
     ]
    }
   ],
   "source": [
    "#load the new data into a dataframe\n",
    "\n",
    "orcidToOrcid = pd.read_csv('data/orcid-to-orcid-tf-idf.tsv',sep='\\t')\n",
    "print(orcidToOrcid.shape)\n",
    "print(orcidToOrcid.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
