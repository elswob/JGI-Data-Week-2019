{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document embedding (doc2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general idea here is to train a neural network model to create text embeddings.\n",
    "Text embedding vectors can then be used to obtrain similarity metrics on neighbouring texts.\n",
    "\n",
    "In this example we use the `doc2vec` model \n",
    "([Le & Mikolov, ICML 2014](https://cs.stanford.edu/~quocle/paragraph_vector.pdf))\n",
    "to create text embeddings using pubmed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/be15516/anaconda3/envs/jgi-data-week-workshop/lib/python3.6/site-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import re\n",
    "import os\n",
    "import collections\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- word2vec -> doc2vec\n",
    "  - skip-gram -> distributed memory\n",
    "  - continuous-bag-of-words -> distributed bag-of-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Distributed Memory model (PV-DM)](https://adriancolyer.files.wordpress.com/2016/05/paragraph-vectors-fig-2.png?w=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Distributed Bag of Words model (PV-DBW)](https://adriancolyer.files.wordpress.com/2016/05/paragraph-vectors-fig-3.png?w=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the pubmed data from earlier sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25475436</td>\n",
       "      <td>2015</td>\n",
       "      <td>Sixty-five common genetic variants and predict...</td>\n",
       "      <td>We developed a 65 type 2 diabetes (T2D) varian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25011450</td>\n",
       "      <td>2014</td>\n",
       "      <td>Association between alcohol and cardiovascular...</td>\n",
       "      <td>To use the rs1229984 variant in the alcohol de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28968714</td>\n",
       "      <td>2018</td>\n",
       "      <td>FATHMM-XF: accurate prediction of pathogenic p...</td>\n",
       "      <td>We present FATHMM-XF, a method for predicting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21965548</td>\n",
       "      <td>2012</td>\n",
       "      <td>Four genetic loci influencing electrocardiogra...</td>\n",
       "      <td>Presence of left ventricular hypertrophy on an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26930047</td>\n",
       "      <td>2016</td>\n",
       "      <td>Diagnosis of Coronary Heart Diseases Using Gen...</td>\n",
       "      <td>Cardiovascular disease (including coronary art...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid  year                                              title  \\\n",
       "0  25475436  2015  Sixty-five common genetic variants and predict...   \n",
       "1  25011450  2014  Association between alcohol and cardiovascular...   \n",
       "2  28968714  2018  FATHMM-XF: accurate prediction of pathogenic p...   \n",
       "3  21965548  2012  Four genetic loci influencing electrocardiogra...   \n",
       "4  26930047  2016  Diagnosis of Coronary Heart Diseases Using Gen...   \n",
       "\n",
       "                                            abstract  \n",
       "0  We developed a 65 type 2 diabetes (T2D) varian...  \n",
       "1  To use the rs1229984 variant in the alcohol de...  \n",
       "2  We present FATHMM-XF, a method for predicting ...  \n",
       "3  Presence of left ventricular hypertrophy on an...  \n",
       "4  Cardiovascular disease (including coronary art...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubmed_data = pd.read_csv(config.demoPubmed, sep=\"\\t\")\n",
    "\n",
    "pubmed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some of the pre-processing steps to be done (subjective):\n",
    "\n",
    "- Make sure `abstract`s are strings.\n",
    "- Keep only abstracts that are sufficiently long enough, and not just fragments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_enough(text, word_length=40, num_sentences=2):\n",
    "    return (len(text.split(\" \")) >= word_length \n",
    "            and text.count(\".\") >= num_sentences)\n",
    "\n",
    "pubmed_data = pubmed_data \\\n",
    "    .assign(abstract=lambda df: df.abstract.astype(str)) \\\n",
    "    .assign(keep=lambda df: df.abstract.apply(long_enough))\n",
    "\n",
    "pubmed_data_keep = pubmed_data.query(\"keep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the rs1229984 variant in the alcohol dehydrogenase 1B gene (ADH1B) as an instrument to investigate the causal role of alcohol in cardiovascular disease. \n",
      "\n",
      "Conclusions. A candidate functional variant, rs28451064, was identified. Future work should focus on identifying the pathway(s) involved. \n",
      "\n",
      "Haptoglobin acts as an antioxidant by limiting peroxidative tissue damage by free hemoglobin. The haptoglobin gene allele Hp2 comprises a 1.7â€‰kb partial duplication. Relative to allele Hp1, Hp2 carriers form protein multimers, suboptimal for hemoglobin scavenging. \n",
      "\n",
      "To establish whether the association between milk intake and prostate cancer operates via the insulin-like growth factor (IGF) pathway (including IGF-I, IGF-II, IGFBP-1, IGFBP-2, and IGFBP-3). \n",
      "\n",
      "Prenatal exposure to maternal cigarette smoking (prenatal smoke exposure) had been associated with altered DNA methylation (DNAm) at birth. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Abstracts to be discarded from the corpus\n",
    "for text in pubmed_data.query(\"not keep\").abstract[:5]:\n",
    "    print(text, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create two sets of text corpus, in which a text element consists of both the `title` and the `abstract`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts in training set: 8379\n",
      "Number of texts in test set: 441\n"
     ]
    }
   ],
   "source": [
    "split = 0.95\n",
    "split_idx = int(np.floor(pubmed_data_keep.shape[0] * split))\n",
    "\n",
    "pubmed_train = pubmed_data_keep[:split_idx]\n",
    "pubmed_test = pubmed_data_keep[split_idx:]\n",
    "train_corpus = []\n",
    "test_corpus = []\n",
    "\n",
    "for i, (title, abstract) in enumerate(zip(pubmed_train.title, \n",
    "                                          pubmed_train.abstract)):\n",
    "    train_corpus.append(TaggedDocument(title + \" \" + abstract, [i]))\n",
    "    \n",
    "for i, (title, abstract) in enumerate(zip(pubmed_test.title,\n",
    "                                          pubmed_test.abstract)):\n",
    "    test_corpus.append(TaggedDocument(title + \" \" + abstract, [i]))\n",
    "    \n",
    "print(f\"Number of texts in training set: {len(train_corpus)}\")\n",
    "print(f\"Number of texts in test set: {len(test_corpus)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaggedDocument(Sixty-five common genetic variants and prediction of type 2 diabetes. We developed a 65 type 2 diabetes (T2D) variant-weighted gene score to examine the impact on T2D risk assessment in a U.K.-based consortium of prospective studies, with subjects initially free from T2D (N = 13,294; 37.3% women; mean age 58.5 [38-99] years). We compared the performance of the gene score with the phenotypically derived Framingham Offspring Study T2D risk model and then the two in combination. Over the median 10 years of follow-up, 804 participants developed T2D. The odds ratio for T2D (top vs. bottom quintiles of gene score) was 2.70 (95% CI 2.12-3.43). With a 10% false-positive rate, the genetic score alone detected 19.9% incident cases, the Framingham risk model 30.7%, and together 37.3%. The respective area under the receiver operator characteristic curves were 0.60 (95% CI 0.58-0.62), 0.75 (95% CI 0.73 to 0.77), and 0.76 (95% CI 0.75 to 0.78). The combined risk score net reclassification improvement (NRI) was 8.1% (5.0 to 11.2; P = 3.31 Ã— 10(-7)). While BMI stratification into tertiles influenced the NRI (BMI â‰¤24.5 kg/m(2), 27.6% [95% CI 17.7-37.5], P = 4.82 Ã— 10(-8); 24.5-27.5 kg/m(2), 11.6% [95% CI 5.8-17.4], P = 9.88 Ã— 10(-5); >27.5 kg/m(2), 2.6% [95% CI -1.4 to 6.6], P = 0.20), age categories did not. The addition of the gene score to a phenotypic risk model leads to a potentially clinically important improvement in discrimination of incident T2D. , [0]) \n",
      "\n",
      "TaggedDocument(FATHMM-XF: accurate prediction of pathogenic point mutations via extended features. We present FATHMM-XF, a method for predicting pathogenic point mutations in the human genome. Drawing on an extensive feature set, FATHMM-XF outperforms competitors on benchmark tests, particularly in non-coding regions where the majority of pathogenic mutations are likely to be found., [1]) \n",
      "\n",
      "TaggedDocument(Four genetic loci influencing electrocardiographic indices of left ventricular hypertrophy. Presence of left ventricular hypertrophy on an ECG (ECG-LVH) is widely assessed clinically and provides prognostic information in some settings. There is evidence for significant heritability of ECG-LVH. We conducted a large-scale gene-centric association analysis of 4 commonly measured indices of ECG-LVH., [2]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(train_corpus[i], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Doc2Vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we demonstrate a simple usage of paragraph / sentence embedding using a Doc2Vec model.\n",
    "\n",
    "Refer to [gensim's documentation](https://radimrehurek.com/gensim/models/doc2vec.html) \n",
    "on the specific usage of Doc2Vec model and its APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 21s, sys: 7.3 s, total: 3min 28s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "d2v_model = Doc2Vec(train_corpus)\n",
    "\n",
    "%time d2v_model.train(train_corpus, total_examples=d2v_model.corpus_count, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mDoc2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdocuments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdm_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdbow_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdm_concat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdm_tag_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdocvecs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdocvecs_mapfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      Class for training, using and evaluating neural networks described in http://arxiv.org/pdf/1405.4053v2.pdf\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Initialize the model from an iterable of `documents`. Each document is a\n",
       "TaggedDocument object that will be used for training.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "documents : iterable of iterables\n",
       "    The `documents` iterable can be simply a list of TaggedDocument elements, but for larger corpora,\n",
       "    consider an iterable that streams the documents directly from disk/network.\n",
       "    If you don't supply `documents`, the model is left uninitialized -- use if\n",
       "    you plan to initialize it in some other way.\n",
       "\n",
       "dm : int {1,0}\n",
       "    Defines the training algorithm. If `dm=1`, 'distributed memory' (PV-DM) is used.\n",
       "    Otherwise, `distributed bag of words` (PV-DBOW) is employed.\n",
       "\n",
       "size : int\n",
       "    Dimensionality of the feature vectors.\n",
       "window : int\n",
       "    The maximum distance between the current and predicted word within a sentence.\n",
       "alpha : float\n",
       "    The initial learning rate.\n",
       "min_alpha : float\n",
       "    Learning rate will linearly drop to `min_alpha` as training progresses.\n",
       "seed : int\n",
       "    Seed for the random number generator. Initial vectors for each word are seeded with a hash of\n",
       "    the concatenation of word + `str(seed)`. Note that for a fully deterministically-reproducible run,\n",
       "    you must also limit the model to a single worker thread (`workers=1`), to eliminate ordering jitter\n",
       "    from OS thread scheduling. (In Python 3, reproducibility between interpreter launches also requires\n",
       "    use of the `PYTHONHASHSEED` environment variable to control hash randomization).\n",
       "min_count : int\n",
       "    Ignores all words with total frequency lower than this.\n",
       "max_vocab_size : int\n",
       "    Limits the RAM during vocabulary building; if there are more unique\n",
       "    words than this, then prune the infrequent ones. Every 10 million word types need about 1GB of RAM.\n",
       "    Set to `None` for no limit.\n",
       "sample : float\n",
       "    The threshold for configuring which higher-frequency words are randomly downsampled,\n",
       "    useful range is (0, 1e-5).\n",
       "workers : int\n",
       "    Use these many worker threads to train the model (=faster training with multicore machines).\n",
       "iter : int\n",
       "    Number of iterations (epochs) over the corpus.\n",
       "hs : int {1,0}\n",
       "    If 1, hierarchical softmax will be used for model training.\n",
       "    If set to 0, and `negative` is non-zero, negative sampling will be used.\n",
       "negative : int\n",
       "    If > 0, negative sampling will be used, the int for negative specifies how many \"noise words\"\n",
       "    should be drawn (usually between 5-20).\n",
       "    If set to 0, no negative sampling is used.\n",
       "dm_mean : int {1,0}\n",
       "    If 0 , use the sum of the context word vectors. If 1, use the mean.\n",
       "    Only applies when `dm` is used in non-concatenative mode.\n",
       "dm_concat : int {1,0}\n",
       "    If 1, use concatenation of context vectors rather than sum/average;\n",
       "    Note concatenation results in a much-larger model, as the input\n",
       "    is no longer the size of one (sampled or arithmetically combined) word vector, but the\n",
       "    size of the tag(s) and all words in the context strung together.\n",
       "dm_tag_count : int\n",
       "    Expected constant number of document tags per document, when using\n",
       "    dm_concat mode; default is 1.\n",
       "dbow_words : int {1,0}\n",
       "    If set to 1 trains word-vectors (in skip-gram fashion) simultaneous with DBOW\n",
       "    doc-vector training; If 0, only trains doc-vectors (faster).\n",
       "trim_rule : function\n",
       "    Vocabulary trimming rule, specifies whether certain words should remain in the vocabulary,\n",
       "    be trimmed away, or handled using the default (discard if word count < min_count).\n",
       "    Can be None (min_count will be used, look to :func:`~gensim.utils.keep_vocab_item`),\n",
       "    or a callable that accepts parameters (word, count, min_count) and returns either\n",
       "    :attr:`gensim.utils.RULE_DISCARD`, :attr:`gensim.utils.RULE_KEEP` or :attr:`gensim.utils.RULE_DEFAULT`.\n",
       "    Note: The rule, if given, is only used to prune vocabulary during build_vocab() and is not stored as part\n",
       "    of the model.\n",
       "callbacks : :obj: `list` of :obj: `~gensim.models.callbacks.CallbackAny2Vec`\n",
       "    List of callbacks that need to be executed/run at specific stages during training.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.local/share/virtualenvs/jgi-data-week-workshop/lib/python3.6/site-packages/gensim/models/doc2vec.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is how you can check the API usage.\n",
    "# You can do this in the notebook kernel session or \n",
    "# in a jupyter lab console session associated to this kernel\n",
    "\n",
    "?Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check of our model fit,\n",
    "we take the first 1000 abstract from the entire train corpus,\n",
    "and see whether for the given text, the most similar abstract is itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_n = 1000\n",
    "sample_corpus = train_corpus[:sample_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "for doc_id in range(len(sample_corpus)):\n",
    "    # The inferred_vector of this document\n",
    "    inferred_vector = d2v_model.infer_vector(sample_corpus[doc_id].words)\n",
    "    # Get the most similar document rankings across entire `train_corpus`\n",
    "    # in the form of\n",
    "    # [(499, 0.7327660322189331),\n",
    "    #  (8835, 0.6161227822303772),\n",
    "    #  (981, 0.5684570074081421),\n",
    "    #  ...]\n",
    "    sims = d2v_model.docvecs.most_similar([inferred_vector], \n",
    "                                          topn=len(d2v_model.docvecs))\n",
    "    # The index position for `doc_id`.\n",
    "    # If this abstract is most similar to itself, rank should be 0\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    \n",
    "    ranks.append(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 992, 1: 7, 11: 1})\n",
      "Accuracy: 99.2%\n"
     ]
    }
   ],
   "source": [
    "print(collections.Counter(ranks))\n",
    "\n",
    "accuracy = np.sum(np.array(ranks) == 0) / sample_n * 100\n",
    "print(f\"Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation engine based on abstract embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose documents from `test_corpus` are from authors that are interested in finding collaborators for future works.\n",
    "\n",
    "For a small sample of `test_corpus` documents, we test to find the most similar documents from `train_corpus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaggedDocument(Adaptation and validation of antibody-ELISA using dried blood spots on filter paper for epidemiological surveys of tsetse-transmitted trypanosomosis in cattle. The indirect enzyme-linked immunosorbent assay (ELISA) for the detection of anti-trypanosomal antibodies in bovine serum was adapted for use with dried blood spots on filter paper. Absorbance (450 nm) results for samples were expressed as percent positivity, i.e. percentage of the median absorbance result of four replicates of the strong positive control serum. The antibody-ELISA was evaluated in Zambia for use in epidemiological surveys of the prevalence of tsetse-transmitted bovine trypanosomosis. Known negative samples (sera, n = 209; blood spots, n = 466) were obtained from cattle from closed herds in tsetse-free areas close to Lusaka. Known positive samples (sera, n = 367; blood spots, n = 278) were obtained from cattle in Zambia's Central, Lusaka and Eastern Provinces, diagnosed as being infected with Trypanosoma brucei, T. congolense, or T. vivax using the phase-contrast buffy-coat technique or Giemsa-stained thick and thin blood smears. For sera (at a cut-off value of 23.0% positivity) sensitivity and specificity were 86.1 and 95.2%, respectively. For bloodspots (at a cut-off value of 18.8% positivity) sensitivity and specificity were 96.8 and 95.7%, respectively. The implications of persistence of antibodies following treatment or self-cure are discussed., [0]) \n",
      "\n",
      "TaggedDocument(How human brucellosis incidence in urban Kampala can be reduced most efficiently? A stochastic risk assessment of informally-marketed milk. In Kampala, Uganda, studies have shown a significant incidence of human brucellosis. A stochastic risk assessment involving two field surveys (cattle farms and milk shops) and a medical record survey was conducted to assess the risk of human brucellosis infection through consumption of informally marketed raw milk potentially infected with Brucella abortus in Kampala and to identify the best control options., [1]) \n",
      "\n",
      "TaggedDocument(Herd prevalence of bovine brucellosis and analysis of risk factors in cattle in urban and peri-urban areas of the Kampala economic zone, Uganda. Human brucellosis has been found to be prevalent in the urban areas of Kampala, the capital city of Uganda. A cross-sectional study was designed to generate precise information on the prevalence of brucellosis in cattle and risk factors for the disease in its urban and peri-urban dairy farming systems., [2]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc_id in range(3):\n",
    "    print(test_corpus[doc_id], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_similar_n = 3\n",
    "similar = []\n",
    "\n",
    "for test_doc_id in range(len(test_corpus)):\n",
    "    words = test_corpus[test_doc_id].words\n",
    "    inferred_vector = d2v_model.infer_vector(words, steps=20)\n",
    "    top_sim = d2v_model.docvecs.most_similar(\n",
    "        [inferred_vector], topn = top_similar_n)\n",
    "    similar.append(top_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank test abstract by similar scores\n",
    "most_similar = []\n",
    "for test_doc_id in range(len(test_corpus)):\n",
    "    item = {\n",
    "        \"test_doc_id\": test_doc_id,\n",
    "        \"train_doc_id\": similar[test_doc_id][0][0],\n",
    "        \"score\": similar[test_doc_id][0][1],\n",
    "    }\n",
    "    most_similar.append(item)\n",
    "    \n",
    "most_similar = pd.DataFrame(most_similar).sort_values(by=\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select top 2 test abstracts that have the best match from `train_corpus`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Abstract 368:\n",
      "content: Regulating Rho GTPases and their regulators. Rho GTPases regulate cytoskeletal and cell adhesion dynamics and thereby coordinate a wide range of cellular processes, including cell migration, cell polarity and cell cycle progression. Most Rho GTPases cycle between a GTP-bound active conformation and a GDP-bound inactive conformation to regulate their ability to activate effector proteins and to elicit cellular responses. However, it has become apparent that Rho GTPases are regulated by post-translational modifications and the formation of specific protein complexes, in addition to GTP-GDP cycling. The canonical regulators of Rho GTPases - guanine nucleotide exchange factors, GTPase-activating proteins and guanine nucleotide dissociation inhibitors - are regulated similarly, creating a complex network of interactions to determine the precise spatiotemporal activation of Rho GTPases.\n",
      "\n",
      "\n",
      "\t ## Matched abstract 0: id 8185, similarity 0.728532075881958\n",
      "\t Regulation of endocytic traffic by Rho GTPases. The members of the Rho subfamily of small GTPases are key regulators of the actin cytoskeleton. However, recent studies have provided evidence for multiple additional roles for these signalling proteins in controlling endocytic traffic. Here we review our current understanding of Rho GTPase action within the endocytic pathway and examine the potential points of convergence with the more established, actin-based functions of these signalling proteins.\n",
      "\n",
      "\n",
      "\t ## Matched abstract 1: id 5598, similarity 0.6669962406158447\n",
      "\t Ran-GTP coordinates regulation of microtubule nucleation and dynamics during mitotic-spindle assembly. It was recently reported that GTP-bound Ran induces microtubule and pseudo-spindle assembly in mitotic egg extracts in the absence of chromosomes and centrosomes, and that chromosomes induce the assembly of spindle microtubules in these extracts through generation of Ran-GTP. Here we examine the effects of Ran-GTP on microtubule nucleation and dynamics and show that Ran-GTP has independent effects on both the nucleation activity of centrosomes and the stability of centrosomal microtubules. We also show that inhibition of Ran-GTP production, even in the presence of duplicated centrosomes and kinetochores, prevents assembly of a bipolar spindle in M-phase extracts.\n",
      "\n",
      "\n",
      "\t ## Matched abstract 2: id 3422, similarity 0.5815297365188599\n",
      "\t Perceptions of patient expectation for an antibiotic: a comparison of walk-in centre nurses and GPs. Patient expectation for a prescription is a recognized influence on GPs' prescribing, particularly in relation to the prescribing of antibiotics. Nurses are now able to supply antibiotics under a Patient Group Direction (PGD) in NHS walk-in centres and may experience similar pressures in this new role.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Abstract 300:\n",
      "content: RhoB controls endothelial barrier recovery by inhibiting Rac1 trafficking to the cell border. Endothelial barrier dysfunction underlies chronic inflammatory diseases. In searching for new proteins essential to the human endothelial inflammatory response, we have found that the endosomal GTPase RhoB is up-regulated in response to inflammatory cytokines and expressed in the endothelium of some chronically inflamed tissues. We show that although RhoB and the related RhoA and RhoC play additive and redundant roles in various aspects of endothelial barrier function, RhoB specifically inhibits barrier restoration after acute cell contraction by preventing plasma membrane extension. During barrier restoration, RhoB trafficking is induced between vesicles containing RhoB nanoclusters and plasma membrane protrusions. The Rho GTPase Rac1 controls membrane spreading and stabilizes endothelial barriers. We show that RhoB colocalizes with Rac1 in endosomes and inhibits Rac1 activity and trafficking to the cell border during barrier recovery. Inhibition of endosomal trafficking impairs barrier reformation, whereas induction of Rac1 translocation to the plasma membrane accelerates it. Therefore, RhoB-specific regulation of Rac1 trafficking controls endothelial barrier integrity during inflammation.\n",
      "\n",
      "\n",
      "\t ## Matched abstract 0: id 8202, similarity 0.7003606557846069\n",
      "\t PRK1 is targeted to endosomes by the small GTPase, RhoB. RhoB has been shown to be an endosomal GTPase both by immunocytochemistry and electron microscopy, however, its role in endocytosis is unknown. Elucidation of the cellular roles of other members of this superfamily of signaling proteins has come with the identification of their downstream partners. We show here that the recently isolated serine/threonine kinase PRK1 is targeted to the endosomal compartment by RhoB. This is established both through immunofluorescence and cell fractionation. PRK1 is shown to interact with activated RhoB in cells and is localized to endosomes through its Rho-binding HR1 domain. Translocation of PRK1 to the endosomal compartment by RhoB is accompanied by a shift in the electrophoretic mobility of the kinase indicative of an accompanying activation.\n",
      "\n",
      "\n",
      "\t ## Matched abstract 1: id 7588, similarity 0.606460452079773\n",
      "\t The retinoblastoma protein interacts with Bag-1 in human colonic adenoma and carcinoma derived cell lines. Although the retinoblastoma susceptibility gene RB1 is inactivated in a wide range of human tumours, overexpression in colonic carcinomas has been linked to the antiapoptotic function of the protein. In the current study we show that the Retinoblastoma susceptibility protein (Rb) protein interacts with Bag-1, an apoptotic regulator, in human colonic adenoma- and carcinoma-derived cell lines. Coimmunoprecipitation demonstrated that endogenous Rb and Bag-1 interact in both adenoma- and carcinoma-derived cell lines. The specificity of the interaction was demonstrated by expression of human Papillomavirus E7 oncoprotein, an inhibitor of Rb protein interactions, which disrupted the Rb/Bag-1 complex. We report that Bag-1 is predominantly localised in the nucleus of colorectal adenoma- and carcinoma-derived epithelial cells. Disruption of the Rb/Bag-1 complex through expression of E7 changes the subcellular distribution of Bag-1, decreasing nuclear localised Bag-1. Our work establishes that the Rb protein interacts with the Bag-1 apoptotic regulator protein, and introduces a novel function for Rb, involving modulation of the subcellular localisation of Bag-1 in human colonic epithelial cells.\n",
      "\n",
      "\n",
      "\t ## Matched abstract 2: id 7601, similarity 0.6036044359207153\n",
      "\t The role of the retinoblastoma protein (Rb) in the nuclear localization of BAG-1: implications for colorectal tumour cell survival. Although the retinoblastoma susceptibility gene RB1 is inactivated in a wide variety of human cancers, the retinoblastoma protein (Rb) has been shown to be overexpressed in colon cancers, which is linked to the anti-apoptotic function of the protein. However, the mechanisms by which Rb regulates apoptosis are yet to be fully elucidated. We have established that Rb interacts with the anti-apoptotic BAG-1 (Bcl-2 associated athanogene-1) protein, and that a decrease in nuclear localization of BAG-1 is detectable when the interaction between Rb and BAG-1 is disrupted by expression of the E7 viral oncoprotein. Interestingly, although reported as deregulated in colorectal cancers, we have found that BAG-1 expression is also altered in small adenomas, where its localization was found to be predominantly nuclear. In addition, we have established that maintenance of high nuclear BAG-1 in vitro increases the resistance of adenoma-derived cells to gamma-radiation-induced apoptosis. Our work suggests a novel function for Rb, involving modulation of the subcellular localization of BAG-1. We have found predominant nuclear BAG-1 localization in small adenomas, and suggest that BAG-1 may promote colorectal tumour cell survival by making colonic epithelial cells less sensitive to DNA damage.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_n = 2\n",
    "preview_n = 3\n",
    "\n",
    "for test_doc_id in most_similar.test_doc_id[:top_n]:\n",
    "    print(f\"# Abstract {test_doc_id}:\")\n",
    "    words = test_corpus[test_doc_id].words\n",
    "    print(f\"content: {words}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    for i in range(preview_n):\n",
    "        train_doc_id = similar[test_doc_id][i][0]\n",
    "        similarity_score = similar[test_doc_id][i][1]\n",
    "        print(f\"\\t ## Matched abstract {i}: id {train_doc_id}, similarity {similarity_score}\")\n",
    "        words = train_corpus[train_doc_id].words\n",
    "        print(f\"\\t {words}\")\n",
    "        print(\"\\n\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feeling lucky with some random text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Early Cannabis Use, Polygenic Risk Score for Schizophrenia and Brain Maturation in Adolescence. Cannabis use during adolescence is known to increase the risk for schizophrenia in men. Sex differences in the dynamics of brain maturation during adolescence may be of particular importance with regard to vulnerability of the male brain to cannabis exposure.',\n",
       " 0.4776185154914856)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Searching for the causal effects of body mass index in over 300 000 participants in UK Biobank, using Mendelian randomization.\"\n",
    "\n",
    "def feeling_lucky(text, model=d2v_model, train_corpus=train_corpus):\n",
    "    inferred_vector = model.infer_vector(text, steps=20)\n",
    "    top_sim = model.docvecs.most_similar(\n",
    "        [inferred_vector], topn = 1)\n",
    "    matched_abstract = train_corpus[top_sim[0][0]].words\n",
    "    similarity_score = top_sim[0][1]\n",
    "    return matched_abstract, similarity_score\n",
    "\n",
    "feeling_lucky(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is a very crude demo (small training set and lack of pre-processing and model tuning).\n",
    "\n",
    "Below is the overall distribution of top similarity scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>test_doc_id</th>\n",
       "      <th>train_doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0.691740</td>\n",
       "      <td>401</td>\n",
       "      <td>8185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>0.684324</td>\n",
       "      <td>266</td>\n",
       "      <td>5645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.673902</td>\n",
       "      <td>278</td>\n",
       "      <td>5645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.671339</td>\n",
       "      <td>153</td>\n",
       "      <td>6701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.670630</td>\n",
       "      <td>103</td>\n",
       "      <td>1537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>0.667665</td>\n",
       "      <td>368</td>\n",
       "      <td>5598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>0.658553</td>\n",
       "      <td>418</td>\n",
       "      <td>2983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.657934</td>\n",
       "      <td>440</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0.655859</td>\n",
       "      <td>293</td>\n",
       "      <td>8185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.648159</td>\n",
       "      <td>253</td>\n",
       "      <td>8185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0.646250</td>\n",
       "      <td>403</td>\n",
       "      <td>5784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.641382</td>\n",
       "      <td>154</td>\n",
       "      <td>4124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.637918</td>\n",
       "      <td>300</td>\n",
       "      <td>7588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.631138</td>\n",
       "      <td>310</td>\n",
       "      <td>5645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0.627528</td>\n",
       "      <td>280</td>\n",
       "      <td>1456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0.625247</td>\n",
       "      <td>354</td>\n",
       "      <td>8183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.622152</td>\n",
       "      <td>94</td>\n",
       "      <td>1537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0.618064</td>\n",
       "      <td>282</td>\n",
       "      <td>2676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0.616937</td>\n",
       "      <td>241</td>\n",
       "      <td>2214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.616568</td>\n",
       "      <td>233</td>\n",
       "      <td>6616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.616462</td>\n",
       "      <td>286</td>\n",
       "      <td>5316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0.616140</td>\n",
       "      <td>314</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.614994</td>\n",
       "      <td>144</td>\n",
       "      <td>3753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.614932</td>\n",
       "      <td>99</td>\n",
       "      <td>2058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>0.613500</td>\n",
       "      <td>412</td>\n",
       "      <td>8021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.613111</td>\n",
       "      <td>260</td>\n",
       "      <td>2168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>0.612647</td>\n",
       "      <td>356</td>\n",
       "      <td>3514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.611959</td>\n",
       "      <td>138</td>\n",
       "      <td>4084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0.610971</td>\n",
       "      <td>435</td>\n",
       "      <td>7515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.609964</td>\n",
       "      <td>36</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.443941</td>\n",
       "      <td>0</td>\n",
       "      <td>5198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.443896</td>\n",
       "      <td>86</td>\n",
       "      <td>4899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0.440439</td>\n",
       "      <td>428</td>\n",
       "      <td>8377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.440070</td>\n",
       "      <td>204</td>\n",
       "      <td>2357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0.436808</td>\n",
       "      <td>373</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.436588</td>\n",
       "      <td>220</td>\n",
       "      <td>3885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.435770</td>\n",
       "      <td>17</td>\n",
       "      <td>965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0.435649</td>\n",
       "      <td>378</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.434879</td>\n",
       "      <td>185</td>\n",
       "      <td>3232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.432100</td>\n",
       "      <td>77</td>\n",
       "      <td>8201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.431435</td>\n",
       "      <td>199</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0.428662</td>\n",
       "      <td>380</td>\n",
       "      <td>3651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0.425344</td>\n",
       "      <td>421</td>\n",
       "      <td>3211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.425193</td>\n",
       "      <td>46</td>\n",
       "      <td>4317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0.424677</td>\n",
       "      <td>325</td>\n",
       "      <td>5882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0.423589</td>\n",
       "      <td>311</td>\n",
       "      <td>6942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.423563</td>\n",
       "      <td>119</td>\n",
       "      <td>3035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.422617</td>\n",
       "      <td>207</td>\n",
       "      <td>4790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.420809</td>\n",
       "      <td>169</td>\n",
       "      <td>2355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.419704</td>\n",
       "      <td>177</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.416716</td>\n",
       "      <td>92</td>\n",
       "      <td>5857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>0.416118</td>\n",
       "      <td>364</td>\n",
       "      <td>5955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.414018</td>\n",
       "      <td>108</td>\n",
       "      <td>5882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.411888</td>\n",
       "      <td>212</td>\n",
       "      <td>2862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.410540</td>\n",
       "      <td>63</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.399272</td>\n",
       "      <td>234</td>\n",
       "      <td>6772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.389932</td>\n",
       "      <td>12</td>\n",
       "      <td>6487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>0.383518</td>\n",
       "      <td>427</td>\n",
       "      <td>1631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.379061</td>\n",
       "      <td>87</td>\n",
       "      <td>2396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.379026</td>\n",
       "      <td>74</td>\n",
       "      <td>4576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        score  test_doc_id  train_doc_id\n",
       "401  0.691740          401          8185\n",
       "266  0.684324          266          5645\n",
       "278  0.673902          278          5645\n",
       "153  0.671339          153          6701\n",
       "103  0.670630          103          1537\n",
       "368  0.667665          368          5598\n",
       "418  0.658553          418          2983\n",
       "440  0.657934          440          1988\n",
       "293  0.655859          293          8185\n",
       "253  0.648159          253          8185\n",
       "403  0.646250          403          5784\n",
       "154  0.641382          154          4124\n",
       "300  0.637918          300          7588\n",
       "310  0.631138          310          5645\n",
       "280  0.627528          280          1456\n",
       "354  0.625247          354          8183\n",
       "94   0.622152           94          1537\n",
       "282  0.618064          282          2676\n",
       "241  0.616937          241          2214\n",
       "233  0.616568          233          6616\n",
       "286  0.616462          286          5316\n",
       "314  0.616140          314           438\n",
       "144  0.614994          144          3753\n",
       "99   0.614932           99          2058\n",
       "412  0.613500          412          8021\n",
       "260  0.613111          260          2168\n",
       "356  0.612647          356          3514\n",
       "138  0.611959          138          4084\n",
       "435  0.610971          435          7515\n",
       "36   0.609964           36           577\n",
       "..        ...          ...           ...\n",
       "0    0.443941            0          5198\n",
       "86   0.443896           86          4899\n",
       "428  0.440439          428          8377\n",
       "204  0.440070          204          2357\n",
       "373  0.436808          373           244\n",
       "220  0.436588          220          3885\n",
       "17   0.435770           17           965\n",
       "378  0.435649          378          4590\n",
       "185  0.434879          185          3232\n",
       "77   0.432100           77          8201\n",
       "199  0.431435          199          1991\n",
       "380  0.428662          380          3651\n",
       "421  0.425344          421          3211\n",
       "46   0.425193           46          4317\n",
       "325  0.424677          325          5882\n",
       "311  0.423589          311          6942\n",
       "119  0.423563          119          3035\n",
       "207  0.422617          207          4790\n",
       "169  0.420809          169          2355\n",
       "177  0.419704          177           471\n",
       "92   0.416716           92          5857\n",
       "364  0.416118          364          5955\n",
       "108  0.414018          108          5882\n",
       "212  0.411888          212          2862\n",
       "63   0.410540           63           403\n",
       "234  0.399272          234          6772\n",
       "12   0.389932           12          6487\n",
       "427  0.383518          427          1631\n",
       "87   0.379061           87          2396\n",
       "74   0.379026           74          4576\n",
       "\n",
       "[441 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [introduction to doc2vec](https://blog.acolyer.org/2016/06/01/distributed-representations-of-sentences-and-documents/)\n",
    "- [sentiment analysis](http://linanqiu.github.io/2015/10/07/word2vec-sentiment/)\n",
    "- https://medium.com/@ermolushka/text-clusterization-using-python-and-doc2vec-8c499668fa61\n",
    "- https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-lee.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
